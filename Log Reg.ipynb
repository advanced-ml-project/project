{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20007, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>vaderMean</th>\n",
       "      <th>vaderStd</th>\n",
       "      <th>vaderCatLabel</th>\n",
       "      <th>vaderCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377384607969013765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>border patrol video shows smugglers abandoning...</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.045958</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>high</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377367836046192641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>gop rep urges hhs to halt reported plan to rel...</td>\n",
       "      <td>80</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>0.495874</td>\n",
       "      <td>high</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377339316616097797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>see it  nasas curiosity rover takes mars selfie</td>\n",
       "      <td>17</td>\n",
       "      <td>0.052776</td>\n",
       "      <td>0.322931</td>\n",
       "      <td>low</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377319049487642625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>trump moving forward with plans to start socia...</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.451982</td>\n",
       "      <td>high</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1377316510939684883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FoxNews</td>\n",
       "      <td>san diego teachers given option to teach migra...</td>\n",
       "      <td>311</td>\n",
       "      <td>-0.051989</td>\n",
       "      <td>0.463370</td>\n",
       "      <td>high</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  topic   source  \\\n",
       "0  1377384607969013765    NaN  FoxNews   \n",
       "1  1377367836046192641    NaN  FoxNews   \n",
       "2  1377339316616097797    NaN  FoxNews   \n",
       "3  1377319049487642625    NaN  FoxNews   \n",
       "4  1377316510939684883    NaN  FoxNews   \n",
       "\n",
       "                                                text  replyCount  vaderMean  \\\n",
       "0  border patrol video shows smugglers abandoning...         108  -0.045958   \n",
       "1  gop rep urges hhs to halt reported plan to rel...          80   0.043459   \n",
       "2    see it  nasas curiosity rover takes mars selfie          17   0.052776   \n",
       "3  trump moving forward with plans to start socia...        1147   0.005348   \n",
       "4  san diego teachers given option to teach migra...         311  -0.051989   \n",
       "\n",
       "   vaderStd vaderCatLabel  vaderCat  \n",
       "0  0.495337          high       1.0  \n",
       "1  0.495874          high       1.0  \n",
       "2  0.322931           low       0.0  \n",
       "3  0.451982          high       1.0  \n",
       "4  0.463370          high       1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('data/tweets_all.csv')\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vaderCat\n",
       "0.0     6611\n",
       "1.0    13396\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby(by='vaderCat').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text, remove_stopwords=True):\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [border, patrol, video, shows, smugglers, aban...\n",
       "1        [gop, rep, urges, hhs, halt, reported, plan, r...\n",
       "2        [see, nasas, curiosity, rover, takes, mars, se...\n",
       "3        [trump, moving, forward, plans, start, social,...\n",
       "4        [san, diego, teachers, given, option, teach, m...\n",
       "                               ...                        \n",
       "20002    [factbox, joe, biden, win, could, mean, financ...\n",
       "20003    [proud, boys, emboldened, trumps, words, lgbtq...\n",
       "20004    [biden, makes, campaign, pitch, miamis, little...\n",
       "20005    [trump, administration, offered, public, confl...\n",
       "20006    [one, person, killed, two, seriously, injured,...\n",
       "Name: tokens, Length: 20007, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tokens'] = tweets['text'].astype(str).apply(tokenize_text)\n",
    "tweets['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14004, 10)\n",
      "(6003, 10)\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = train_test_split(tweets, train_size = 0.7, random_state=42)\n",
    "y_tr = training_data['vaderCat']\n",
    "y_te = test_data['vaderCat']\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(train, test, description):\n",
    "    '''\n",
    "    Extracts features for Bag of words, Bag of n-grams \n",
    "    or Tf-Idf\n",
    "    '''\n",
    "    \n",
    "    if description == \"bow\" or description == \"tfidf\":\n",
    "        transform = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "        X_tr = transform.fit_transform(train)\n",
    "        X_te = transform.transform(test)\n",
    "        print(description, ': the size of the voc is', len(transform.vocabulary_))\n",
    "        \n",
    "    elif description == \"ngram\":\n",
    "        transform = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[3,3], lowercase=False)\n",
    "        X_tr = transform.fit_transform(train)\n",
    "        X_te = transform.transform(test)\n",
    "        print(description, ': the size of the voc is', len(transform.vocabulary_))\n",
    "        \n",
    "        \n",
    "    if description == \"tfidf\":\n",
    "        transform = text.TfidfTransformer(norm=None)\n",
    "        X_tr = transform.fit_transform(X_tr)\n",
    "        X_te = transform.transform(X_te) \n",
    "        \n",
    "    print('The shape of the df is:', X_tr.shape)   \n",
    "    \n",
    "    return X_tr, X_te, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow : the size of the voc is 18771\n",
      "The shape of the df is: (14004, 18771)\n",
      "ngram : the size of the voc is 138801\n",
      "The shape of the df is: (14004, 138801)\n",
      "tfidf : the size of the voc is 18771\n",
      "The shape of the df is: (14004, 18771)\n"
     ]
    }
   ],
   "source": [
    "X_tr_bow, X_te_bow, tr_bow = feature_extraction(training_data['tokens'], test_data['tokens'], \"bow\")\n",
    "X_tr_ngram, X_te_ngram, tr_ngram = feature_extraction(training_data['tokens'], test_data['tokens'], \"ngram\")\n",
    "X_tr_tfidf, X_te_tfidf, tr_tfidf = feature_extraction(training_data['tokens'], test_data['tokens'], \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aapi community indeed',\n",
       " 'aapi hate group',\n",
       " 'aapisherose trending twitter',\n",
       " 'aari mcdonald carried',\n",
       " 'aaron baseball legend',\n",
       " 'aaron danielson supporter',\n",
       " 'aaron rodgers hilarious',\n",
       " 'aaron rodgers packers',\n",
       " 'aaron rodgers takes',\n",
       " 'aaron wrote nasty',\n",
       " 'aback erdogan colleague',\n",
       " 'aback turkish president',\n",
       " 'abajo durante cinco',\n",
       " 'abandon claims u',\n",
       " 'abandon measures global',\n",
       " 'abandon talks bold',\n",
       " 'abandoned apartment blocks',\n",
       " 'abandoned breakaway project',\n",
       " 'abandoned campfire driven',\n",
       " 'abandoned contentious plan',\n",
       " 'abandoned donkeys pampered',\n",
       " 'abandoned oil gas',\n",
       " 'abandoned pets refers',\n",
       " 'abandoned president trump',\n",
       " 'abandoned soccer competition',\n",
       " 'abandoned town pripyat',\n",
       " 'abandoned vessel adrift',\n",
       " 'abandoning myanmar gas',\n",
       " 'abandoning pledge work']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ngram.get_feature_names()[1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_ = {'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "\n",
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
    "    model = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model\n",
    "\n",
    "def grid_logistic_classify(X_tr, y_tr, X_test, y_test, description, param_grid=param_grid_):\n",
    "    grid = GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
    "    model = grid.fit(X_tr, y_tr)\n",
    "    score = model.best_estimator_.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.6683325004164584\n",
      "Test Score with n-grams features 0.6759953356655006\n",
      "Test Score with tfidf features 0.6358487422955189\n"
     ]
    }
   ],
   "source": [
    "model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "model_bow_tr = simple_logistic_classify(X_tr_ngram, y_tr, X_te_ngram, y_te, 'n-grams')\n",
    "model_tfidf_tr = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vaderCat\n",
       "0.0    2003\n",
       "1.0    4000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby(by='vaderCat').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred\n",
       "0.0    1969\n",
       "1.0    4034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y_pred'] = model_tfidf_tr.predict(X_te_tfidf)\n",
    "test_data.groupby(by='y_pred').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 893 1110]\n",
      " [1076 2924]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44583125, 0.731     ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy by category\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#test_data.loc[test_data['vaderCat'] != test_data['y_pred']].groupby(by='vaderCat').size()\n",
    "matrix = confusion_matrix(y_te, test_data['y_pred'])\n",
    "print(matrix)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most important features\n",
      "--------> bow\n",
      "['guns', 'hate', 'atlanta', 'wrong', 'chauvin', 'xinjiang', 'cover', 'origin', 'levels', 'cuomos', 'freed', 'slams', 'freedom', 'vast', 'limited', 'regional', 'welcomed', 'fda', 'jacob', 'elite']\n",
      "--------> ngram\n",
      "['trial derek chauvin', 'democratic national convention', 'derek chauvin trial', 'judge amy coney', 'first presidential debate', 'new york times', 'president trump said', 'presidential nominee joe', 'joe biden said', 'president trump says', 'year old boy', 'black lives matter', 'president donald trump', 'trump joe biden', 'democratic presidential nominee', 'shooting jacob blake', 'tested positive coronavirus', 'united arab emirates', 'president donald trumps', 'speaker nancy pelosi']\n"
     ]
    }
   ],
   "source": [
    "#class 0\n",
    "print('most important features')\n",
    "print('--------> bow')\n",
    "bow_coef0 = model_bow.coef_[0]\n",
    "imp0 = bow_coef0.argsort()[-20:][::-1]\n",
    "features = tr_bow.get_feature_names()\n",
    "print([features[index] for index in imp0])\n",
    "print('--------> ngram')\n",
    "ngram_coef0 = model_bow_tr.coef_[0]\n",
    "imp0 = ngram_coef0.argsort()[-20:][::-1]\n",
    "features = tr_ngram.get_feature_names()\n",
    "print([features[index] for index in imp0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6625020822921872"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW\n",
    "pipeline = make_pipeline((SMOTE(random_state=0)), LogisticRegression(random_state=0))\n",
    "#model\n",
    "params = {'logisticregression__penalty': ['l2'],\n",
    "          'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "          'logisticregression__solver': ['lbfgs']}\n",
    "\n",
    "grid_bow = GridSearchCV(estimator=pipeline,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    return_train_score=True,\n",
    "                    #scoring= ['accuracy', 'precision', 'recall'],\n",
    "                    #refit = 'recall'\n",
    "                     )\n",
    "\n",
    "grid_bow.fit(X_tr_bow, y_tr)\n",
    "score = grid_bow.best_estimator_.score(X_te_bow, y_te)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4586040313176745"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW\n",
    "pipeline = make_pipeline((SMOTE(random_state=0)), LogisticRegression(multi_class=\"multinomial\", random_state=0))\n",
    "#model\n",
    "params = {'logisticregression__penalty': ['l2'],\n",
    "          'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "          'logisticregression__solver': ['lbfgs']}\n",
    "\n",
    "grid_ngram = GridSearchCV(estimator=pipeline,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    return_train_score=True,\n",
    "                    #scoring= ['accuracy', 'precision', 'recall'],\n",
    "                    #refit = 'recall'\n",
    "                     )\n",
    "\n",
    "grid_ngram.fit(X_tr_ngram, y_tr)\n",
    "score = grid_ngram.best_estimator_.score(X_te_ngram, y_te)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6516741629185407"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW\n",
    "pipeline = make_pipeline((SMOTE(random_state=0)), LogisticRegression(multi_class=\"multinomial\", random_state=0))\n",
    "#model\n",
    "params = {'logisticregression__penalty': ['l2'],\n",
    "          'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "          'logisticregression__solver': ['lbfgs']}\n",
    "\n",
    "grid_tfidf = GridSearchCV(estimator=pipeline,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    return_train_score=True,\n",
    "                    #scoring= ['accuracy', 'precision', 'recall'],\n",
    "                    #refit = 'recall'\n",
    "                     )\n",
    "\n",
    "grid_tfidf.fit(X_tr_tfidf, y_tr)\n",
    "score = grid_tfidf.best_estimator_.score(X_te_tfidf, y_te)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred\n",
       "0.0    1990\n",
       "1.0    4013\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y_pred'] = grid_tfidf.best_estimator_.predict(X_te_tfidf)\n",
    "test_data.groupby(by='y_pred').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 951 1052]\n",
      " [1039 2961]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.47478782, 0.74025   ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy by category tfidf\n",
    "matrix = confusion_matrix(y_te, test_data['y_pred'])\n",
    "print(matrix)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.6873230051640846\n",
      "Test Score with n-grams features 0.6759953356655006\n",
      "Test Score with tfidf features 0.6898217557887723\n"
     ]
    }
   ],
   "source": [
    "model_bow = grid_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "model_bow_tr = grid_logistic_classify(X_tr_ngram, y_tr, X_te_ngram, y_te, 'n-grams')\n",
    "model_tfidf_transform = grid_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow_tr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_bow.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred\n",
       "0.0     685\n",
       "1.0    5318\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['y_pred'] = model_tfidf_transform.best_estimator_.predict(X_te_tfidf)\n",
    "test_data.groupby(by='y_pred').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 413 1590]\n",
      " [ 272 3728]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.20619071, 0.932     ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy by category\n",
    "#test_data.loc[test_data['vaderCat'] != test_data['y_pred']].groupby(by='vaderCat').size()\n",
    "matrix = confusion_matrix(y_te, test_data['y_pred'])\n",
    "print(matrix)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
